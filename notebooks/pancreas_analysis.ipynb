{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Pancreas Data Analysis Pipeline\n",
    "\n",
    "This notebook provides an end-to-end pipeline for pancreas data analysis:\n",
    "- Data loading and preprocessing with multiple options\n",
    "- HVG selection and validation\n",
    "- Normalization and quality control\n",
    "- Visualization and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import scanpy as sc\n",
    "import scib \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import scgpt as scg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from anndata._warnings import OldFormatWarning\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=OldFormatWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "plt.style.context('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration and Directory Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories():\n",
    "    \"\"\"Set up necessary directories and paths\"\"\"\n",
    "    repo_dir = Path.cwd().parent.absolute()\n",
    "    data_dir = repo_dir / \"data\"\n",
    "    save_dir = repo_dir / \"save\"\n",
    "    \n",
    "    # Create directories if they don't exist\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    return repo_dir, data_dir, save_dir\n",
    "\n",
    "# Set up configuration\n",
    "config = {\n",
    "    \"file_path\": \"human_pancreas_norm_complexBatch.h5ad\",\n",
    "    \"n_top_genes\": 1800,\n",
    "    \"gene_col\": \"gene_name\",\n",
    "    \"cell_type_key\": \"celltype\",\n",
    "    \"batch_key\": \"tech\",\n",
    "    \"normalize_total\": 1e4,\n",
    "    \"binning\": 10,\n",
    "    \"use_hvg\": True\n",
    "}\n",
    "\n",
    "# Set up directories\n",
    "repo_dir, data_dir, save_dir = setup_directories()\n",
    "print(f\"Repository directory: {repo_dir}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Save directory: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_scanpy(file_path, n_top_genes=1800, hvg=True, show_info=True):\n",
    "    \"\"\"Load and preprocess data using scanpy pipeline\"\"\"\n",
    "    adata = sc.read_h5ad(file_path)\n",
    "    \n",
    "    # HVG selection if requested\n",
    "    if hvg and 'highly_variable' not in adata.var.columns:\n",
    "        sc.pp.highly_variable_genes(\n",
    "            adata, \n",
    "            n_top_genes=n_top_genes, \n",
    "            flavor='seurat_v3'\n",
    "        )\n",
    "        adata = adata[:, adata.var['highly_variable']]\n",
    "    \n",
    "    # Check and perform normalization if needed\n",
    "    if adata.X.max() > 10:\n",
    "        print(\"Performing normalization...\")\n",
    "        sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "        sc.pp.log1p(adata)\n",
    "    else:\n",
    "        print(\"Data appears to be already normalized\")\n",
    "    \n",
    "    if show_info:\n",
    "        print_data_info(adata)\n",
    "    \n",
    "    return adata\n",
    "\n",
    "def load_data_scgpt(file_path, config):\n",
    "    \"\"\"Load and preprocess data using scGPT pipeline\"\"\"\n",
    "    adata = sc.read_h5ad(file_path)\n",
    "    \n",
    "    preprocessor = scg.preprocess.Preprocessor(\n",
    "        use_key=\"X\",\n",
    "        filter_gene_by_counts=10,\n",
    "        filter_cell_by_counts=10,\n",
    "        normalize_total=config[\"normalize_total\"],\n",
    "        result_normed_key=\"X_normed\",\n",
    "        log1p=True,\n",
    "        result_log1p_key=\"X_log1p\",\n",
    "        subset_hvg=config[\"use_hvg\"],\n",
    "        hvg_flavor=\"seurat_v3\",\n",
    "        binning=config[\"binning\"],\n",
    "        result_binned_key=\"X_binned\",\n",
    "    )\n",
    "    \n",
    "    preprocessor(adata, batch_key=config[\"batch_key\"])\n",
    "    return adata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quality Control and Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(adata):\n",
    "    \"\"\"Print comprehensive information about the AnnData object\"\"\"\n",
    "    print(\"\\n=== Data Information ===\")\n",
    "    print(f\"AnnData object: {adata}\")\n",
    "    print(f\"Shape: {adata.shape}\")\n",
    "    \n",
    "    # Matrix information\n",
    "    print(\"\\nMatrix Information:\")\n",
    "    print(f\"X storage type: {type(adata.X)}\")\n",
    "    if scipy.sparse.issparse(adata.X):\n",
    "        print(\"Sparse matrix details:\")\n",
    "        print(f\"- data shape: {adata.X.data.shape}\")\n",
    "        print(f\"- indices shape: {adata.X.indices.shape}\")\n",
    "        print(f\"- indptr shape: {adata.X.indptr.shape}\")\n",
    "    \n",
    "    # Content information\n",
    "    print(\"\\nAvailable annotations:\")\n",
    "    print(f\"Observations (obs): {adata.obs.columns.tolist()}\")\n",
    "    print(f\"Variables (var): {adata.var.columns.tolist()}\")\n",
    "    \n",
    "    if 'highly_variable' in adata.var.columns:\n",
    "        n_hvg = adata.var['highly_variable'].sum()\n",
    "        print(f\"\\nHVG Information:\")\n",
    "        print(f\"Number of highly variable genes: {n_hvg}\")\n",
    "\n",
    "def validate_preprocessing(adata):\n",
    "    \"\"\"Validate the preprocessing steps\"\"\"\n",
    "    checks = {\n",
    "        \"Size\": adata.n_obs > 0 and adata.n_vars > 0,\n",
    "        \"Normalization\": adata.X.max() <= 10,\n",
    "        \"Annotations\": all(key in adata.obs.columns for key in ['tech', 'celltype']),\n",
    "        \"HVG\": 'highly_variable' in adata.var.columns if config[\"use_hvg\"] else True\n",
    "    }\n",
    "    \n",
    "    print(\"\\n=== Validation Results ===\")\n",
    "    for check, result in checks.items():\n",
    "        print(f\"{check}: {'✓' if result else '✗'}\")\n",
    "    \n",
    "    return all(checks.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "file_path = data_dir / config[\"file_path\"]\n",
    "print(\"Loading and processing data...\")\n",
    "\n",
    "try:\n",
    "    # Try scGPT preprocessing first\n",
    "    adata = load_data_scgpt(file_path, config)\n",
    "    print(\"Successfully used scGPT preprocessing\")\n",
    "except Exception as e:\n",
    "    print(f\"scGPT preprocessing failed: {e}\")\n",
    "    print(\"Falling back to scanpy preprocessing...\")\n",
    "    adata = load_data_scanpy(file_path, config[\"n_top_genes\"])\n",
    "\n",
    "# Validate the preprocessing\n",
    "validation_result = validate_preprocessing(adata)\n",
    "print(f\"\\nPreprocessing validation: {'Passed' if validation_result else 'Failed'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualizations(adata):\n",
    "    \"\"\"Create and display visualizations\"\"\"\n",
    "    # UMAP visualization\n",
    "    sc.pp.neighbors(adata)\n",
    "    sc.tl.umap(adata)\n",
    "    \n",
    "    # Cell type UMAP\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc.pl.umap(adata, color='celltype', title='Cell Types', show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Batch effect UMAP\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sc.pl.umap(adata, color='tech', title='Batch Effects', show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Gene expression visualization if HVG is available\n",
    "    if 'highly_variable' in adata.var.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sc.pl.highly_variable_genes(adata, show=False)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "create_visualizations(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(adata, save_dir, config):\n",
    "    \"\"\"Save processed data with appropriate naming\"\"\"\n",
    "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M')\n",
    "    \n",
    "    # Determine filename based on processing\n",
    "    suffix = '_hvg' if config[\"use_hvg\"] else ''\n",
    "    filename = f\"pancreas_processed{suffix}_{timestamp}.h5ad\"\n",
    "    \n",
    "    # Save the file\n",
    "    save_path = save_dir / filename\n",
    "    adata.write_h5ad(save_path)\n",
    "    print(f\"Saved processed data to: {save_path}\")\n",
    "    \n",
    "    return save_path\n",
    "\n",
    "# Save the processed data\n",
    "processed_path = save_processed_data(adata, save_dir, config)\n",
    "print(\"Analysis pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
}