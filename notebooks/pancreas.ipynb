# %% [markdown]
# # Enhanced Pancreas Cell Analysis with scGPT
# 
# This notebook provides a comprehensive analysis of pancreatic cell data using scGPT embeddings.
# We'll perform:
# - Data loading and validation
# - Embedding analysis
# - Dimensionality reduction
# - Batch effect analysis
# - Machine learning model comparison

# %% [markdown]
# ## 1. Setup and Imports

# %%
# Import required libraries
from pathlib import Path
import warnings
import scanpy as sc
import scib 
import numpy as np
import pandas as pd
import sys 
import scgpt as scg
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import GroupShuffleSplit
from sklearn.metrics import classification_report
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
import umap

# Set plotting style
plt.style.context('default')
warnings.filterwarnings('ignore')

# Set random seed for reproducibility
np.random.seed(42)

# %% [markdown]
# ## 2. Data Loading and Initial Processing

# %%
# Define file paths and parameters
hvg_file = Path("C:/Users/annel/OneDrive/Documenten/Machine Learning/scGPT/save/adata_hvg.h5ad")
embed_file = Path("C:/Users/annel/OneDrive/Documenten/Machine Learning/scGPT/data/human_pancreas_norm_complexBatch_embedded.h5ad")

# Load HVG data
if hvg_file.exists():
    print(f"Loading existing HVG AnnData file from {hvg_file}")
    adata = sc.read_h5ad(hvg_file)
    print(f"Loaded AnnData with shape: {adata.shape}")
else:
    print("No existing HVG AnnData file found")

# Set up parameters
gene_col = "gene_name"
cell_type_key = "celltype"
batch_key = "tech"
N_HVG = 1800

# %% [markdown]
# ## 3. Load and Analyze Embeddings

# %%
# Load embedded data
adata_embed = sc.read_h5ad(embed_file)
print("\nEmbedded data information:")
print(adata_embed)

# Create dataframe from embeddings
embeddings_df = pd.DataFrame(adata_embed.obsm["X_scGPT"])
print("\nFirst few rows of scGPT embeddings:")
print(embeddings_df.head())

# Basic statistics
print("\nEmbedding Statistics:")
print(embeddings_df.describe())

# %% [markdown]
# ## 4. Create Train/Test Split

# %%
# Create reference and query datasets
mask = np.random.rand(len(adata_embed)) < 0.8

# Create a column indicating whether each cell is from reference or query set
adata_embed.obs["is_ref"] = ["Reference" if m else "Query" for m in mask]
adata_embed.obs["is_ref"] = adata_embed.obs["is_ref"].astype("category")

# Split the data
adata_ref = adata_embed[mask].copy()
adata_query = adata_embed[~mask].copy()

print(f"Reference dataset shape: {adata_ref.shape}")
print(f"Query dataset shape: {adata_query.shape}")

# %% [markdown]
# ## 5. Visualization with UMAP

# %%
# Prepare UMAP visualization
reducer = umap.UMAP(random_state=42)
random_indices = np.random.choice(adata_embed.shape[0], size=2000, replace=False)
umap_embeddings = reducer.fit_transform(adata_embed.obsm["X_scGPT"][random_indices])

# Create UMAP plot
plt.figure(figsize=(12, 8))
scatter = plt.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1],
                     c=adata_embed.obs.celltype.cat.codes[random_indices],
                     cmap='tab20', alpha=0.6)
plt.title("UMAP Visualization of Pancreas Cell Types")
plt.colorbar(scatter, label="Cell Type")
plt.show()

# %% [markdown]
# ## 6. Batch Effect Analysis

# %%
# Visualize batch effects
plt.figure(figsize=(12, 6))
sns.boxplot(data=embeddings_df.iloc[:, :10], orient="h")
plt.title("Distribution of First 10 Embedding Dimensions")
plt.tight_layout()
plt.show()

# Create batch effect summary
batch_summary = pd.crosstab(adata_embed.obs[batch_key], 
                           adata_embed.obs[cell_type_key])
print("\nBatch distribution across cell types:")
print(batch_summary)

# %% [markdown]
# ## 7. Machine Learning Model Comparison

# %%
# Prepare data for modeling
X = pd.DataFrame(adata_embed.obsm["X_scGPT"])
y = adata_embed.obs[cell_type_key]

# Create train/test split considering batch effects
gss = GroupShuffleSplit(n_splits=1, test_size=0.3, random_state=42)
train_idx, test_idx = next(gss.split(X, y, groups=adata_embed.obs[batch_key]))

X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

# Train and evaluate models
models = {
    "KNN": KNeighborsClassifier(n_neighbors=10),
    "Random Forest": RandomForestClassifier(random_state=42),
    "LightGBM": LGBMClassifier(random_state=42, class_weight="balanced")
}

results = []
for name, model in models.items():
    print(f"\nTraining {name}...")
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    
    report = classification_report(y_test, y_pred, output_dict=True)
    results.append({
        'model': name,
        'macro_avg_f1': report['macro avg']['f1-score'],
        'weighted_avg_f1': report['weighted avg']['f1-score']
    })
    
    print(f"\n{name} Classification Report:")
    print(classification_report(y_test, y_pred))

# Show final results
results_df = pd.DataFrame(results)
print("\nFinal Model Comparison:")
print(results_df)

# %% [markdown]
# ## 8. Save Results and Embeddings

# %%
# Save the processed data
adata_embed.write_h5ad("pancreas_analysis_results.h5ad")
results_df.to_csv("model_comparison_results.csv")

print("Analysis complete! Results have been saved.")